# -*- coding: utf-8 -*-
"""Train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tH_pBMj5ihm8Ou9QDlXvlG38_Z3cVxkF
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

from google.colab import drive
drive.mount('/content/gdrive')

root_path = 'gdrive/My Drive/Hackerearth_DL_Hackathon/'
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras import backend as K
from keras.preprocessing import image
import numpy as np
import os
import PIL

from keras import optimizers
from tensorflow.keras.optimizers import Adam
""
img_width, img_height = 96, 96
nb_filters1 = 32
nb_filters2 = 64
nb_filters3 = 128
conv1_size = 2
conv2_size = 3
conv3_size = 4
pool_size = 2
classes_num = 3
lr = 0.05
batch_size = 32

model = Sequential()
model.add(Conv2D( nb_filters1, (conv1_size, conv1_size), input_shape=[img_width,img_height,3]))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))

model.add(Conv2D( nb_filters2, (conv2_size, conv2_size)))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))

model.add(Conv2D( nb_filters3, (conv3_size, conv3_size)))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))


model.add(Flatten())
model.add(Dense(256)) #256
model.add(Activation("relu"))
model.add(Dropout(0.5))
model.add(Dense(classes_num, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer=optimizers.RMSprop(lr=lr),
              # optimizer = optimizers.Adam(learning_rate=lr),
              # optimizer = 'Adam',
              metrics=['accuracy'])

train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1. / 255)
train_data_path = root_path + 'train_data'
validation_data_path = root_path + 'val_data'

train_generator = train_datagen.flow_from_directory(
    train_data_path,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
    validation_data_path,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical')

epochs = 10

model.fit_generator(
    train_generator,
    # steps_per_epoch=samples_per_epoch,
    epochs=epochs,
    validation_data=validation_generator,
    # callbacks=cbks,
    # validation_steps=validation_steps
    )

target_dir = root_path + 'models/'
if not os.path.exists(target_dir):
  os.mkdir(target_dir)
model.save(root_path + '/models/model.h5')
model.save_weights(root_path +  '/models/weights.h5')

images = []
ans = []
for img in os.listdir(root_path+'/Test Data'):
    img = os.path.join(root_path+'/Test Data', img)
    name = img.split('/')[-1]
    img = image.load_img(img, target_size=(img_width,img_height))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    images.append(img)
    result = model.predict(img)
    x = np.argmax(result[0])
    if x == 0 :
      val = 'Adults'
    elif x == 1:
      val = 'Teenagers'
    else :
      val = 'Toddler'
    ans.append([name, val])

import pandas as pd
ans_df = pd.DataFrame(ans)
test_df = pd.read_csv(root_path+'Test.csv')
ans_df = ans_df.rename(columns = {0:'Filename'})
joined = pd.merge(test_df,ans_df,how='left',left_on='Filename',right_on ='Filename')
joined = joined.rename(columns = {1:'Category'})
joined.to_csv(root_path + 'pred.csv',index=False)

